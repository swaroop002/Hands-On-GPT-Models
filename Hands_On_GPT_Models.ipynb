{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Hands-On GPT Models: Exploring Advanced Language Processing with Hugging Face Transformers**\n",
        "\n",
        "### Welcome to the \"Hands-On GPT Models\" Jupyter Notebook! In this interactive exploration, we embark on a journey to uncover the capabilities of state-of-the-art language models provided by the Hugging Face Transformers library. This hands-on project is designed to be informative and engaging, suitable for both beginners and experienced practitioners in natural language processing (NLP).\n",
        "\n",
        "##**Overview:**\n",
        "###**Text Generation with GPT-2:**\n",
        "  Discover the power of GPT-2 in generating creative and contextually relevant text based on given prompts.\n",
        "\n",
        "###**Sentiment Analysis with DistilBERT:**\n",
        "  Dive into sentiment analysis using DistilBERT to understand the emotional tone of various sentences.\n",
        "\n",
        "###**Text Summarization with DistilBART:**\n",
        "  Explore the art of summarization with DistilBART, distilling long articles into concise and informative summaries.\n",
        "\n",
        "###**Named Entity Recognition (NER) with BERT:**\n",
        "  Uncover named entities within text using BERT, a bidirectional transformer model, for advanced information extraction.\n",
        "\n",
        "###**Question Answering with DistilBERT:**\n",
        "  Engage in dynamic question-answering tasks, extracting relevant information from a given context using DistilBERT."
      ],
      "metadata": {
        "id": "WqEpkTuLNVTv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2con7JLO8W1k"
      },
      "outputs": [],
      "source": [
        "# Importing the required module from the Hugging Face Transformers library\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Text Generation using GPT-2**"
      ],
      "metadata": {
        "id": "H_W88Y8ZQ6qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a text generation pipeline using the GPT-2 model\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# Generating multiple sequences based on a prompt\n",
        "generator(\"I read a good novel.\", max_length=30, num_return_sequences=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugLYNHRk8dUw",
        "outputId": "2d359991-af4a-4aec-9a16-68b788e08534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"I read a good novel.\\n\\n\\nYou're probably wondering who the real author of all the books on this list is. Some of the reasons were\"},\n",
              " {'generated_text': 'I read a good novel. I read an essay. I read what George Orwell wrote a long time ago, and I said to myself, this is'},\n",
              " {'generated_text': 'I read a good novel. The story tells some of the story behind how you start your life, not how you lose your love.\\n\\nI'},\n",
              " {'generated_text': 'I read a good novel. They used to be people you could write about with some sympathy.\\n\\nThis sort of thinking has been going on for'},\n",
              " {'generated_text': 'I read a good novel. Every time I read a word, it was with excitement, like a game where every character I mentioned would be doing something'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating sequences for a different prompt\n",
        "generator(\"We went on a movie date.\", max_length=30, num_return_sequences=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT8aRi-DRIvg",
        "outputId": "718262c9-8d22-421c-adb7-57af547b0069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'We went on a movie date. There were so many stars on set.\"\\n\\nThe actress was particularly excited for the movie about her friend, who'},\n",
              " {'generated_text': 'We went on a movie date. We went down there in the studio after that and got married. We stayed three days. My partner of two years'},\n",
              " {'generated_text': 'We went on a movie date. He got tired of watching the stuff. He went to bed, and the movie date was never over because it was'},\n",
              " {'generated_text': 'We went on a movie date. I was like \"Oh shit.\" And they never told me what happened because this guy was out for lunch. So'},\n",
              " {'generated_text': \"We went on a movie date. My wife and I were standing in front of my bedroom for what seemed like an hour. I didn't realize it\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sentiment Analysis using DistilBERT**"
      ],
      "metadata": {
        "id": "KBb1SKyZRNMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a sentiment analysis pipeline using the DistilBERT model\n",
        "sentiment_analyzer = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
        "\n",
        "# Defining a list of sentences for sentiment analysis\n",
        "sentences = [\n",
        "    \"I love this product! It's amazing.\",\n",
        "    \"The weather today is quite gloomy.\",\n",
        "    \"The movie was not good.\",\n",
        "    \"This restaurant serves delicious food.\"\n",
        "]\n",
        "\n",
        "# Analyzing sentiment for each sentence and printing the results\n",
        "for sentence in sentences:\n",
        "    result = sentiment_analyzer(sentence)\n",
        "    print(f\"Sentence: '{sentence}'\\nSentiment: {result[0]['label']} ({result[0]['score']:.4f})\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9oD4JcJ9k7b",
        "outputId": "d00cdf55-8d33-41b7-8ce6-c7cf280113a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: 'I love this product! It's amazing.'\n",
            "Sentiment: POSITIVE (0.9999)\n",
            "\n",
            "Sentence: 'The weather today is quite gloomy.'\n",
            "Sentiment: NEGATIVE (0.9939)\n",
            "\n",
            "Sentence: 'The movie was not good.'\n",
            "Sentiment: NEGATIVE (0.9998)\n",
            "\n",
            "Sentence: 'This restaurant serves delicious food.'\n",
            "Sentiment: POSITIVE (0.9999)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text Summarization using DistilBART**"
      ],
      "metadata": {
        "id": "A-CC4Na1Rryh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a summarization pipeline using the DistilBART model\n",
        "summarizer = pipeline('summarization', model='sshleifer/distilbart-cnn-12-6')\n",
        "\n",
        "# Providing an article for summarization\n",
        "article = \"\"\"\n",
        "Hubble Space Telescope has captured a stunning image of a distant galaxy.\n",
        "The galaxy, known as NGC 4680, is located in the constellation of Hydra.\n",
        "It is a spiral galaxy with arms stretching outward from a bright central core.\n",
        "The image reveals intricate details of the galaxy's structure, including numerous stars and dust clouds.\n",
        "Scientists use such images to study the formation and evolution of galaxies in the universe.\n",
        "\"\"\"\n",
        "\n",
        "# Generating a summary for the article and printing the original and generated summaries\n",
        "summary = summarizer(article, max_length=150, min_length=50, length_penalty=2.0, num_beams=4)\n",
        "print(\"Original Article:\")\n",
        "print(article)\n",
        "print(\"\\nGenerated Summary:\")\n",
        "print(summary[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwDmo84j-BWA",
        "outputId": "6f8f3449-6d19-4cac-c4ce-ebd8bcd44556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 150, but your input_length is only 90. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Article:\n",
            "\n",
            "Hubble Space Telescope has captured a stunning image of a distant galaxy.\n",
            "The galaxy, known as NGC 4680, is located in the constellation of Hydra.\n",
            "It is a spiral galaxy with arms stretching outward from a bright central core.\n",
            "The image reveals intricate details of the galaxy's structure, including numerous stars and dust clouds.\n",
            "Scientists use such images to study the formation and evolution of galaxies in the universe.\n",
            "\n",
            "\n",
            "Generated Summary:\n",
            " Hubble Space Telescope captures image of galaxy known as NGC 4680 . It is a spiral galaxy with arms stretching outward from a bright central core . The image reveals intricate details of the galaxy's structure, including numerous stars and dust clouds . Scientists use such images to study the formation and evolution of galaxies in the universe .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Named Entity Recognition (NER) using BERT**"
      ],
      "metadata": {
        "id": "n5ZYWLhPR4zF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a named entity recognition (NER) pipeline using the BERT model\n",
        "ner_analyzer = pipeline('ner', model='dbmdz/bert-large-cased-finetuned-conll03-english')\n",
        "\n",
        "# Analyzing named entities in a given text and printing the results\n",
        "entities = ner_analyzer(\"Apple Inc. is planning to open a new store in Paris.\")\n",
        "print(entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0Q_RLVmE9Xw",
        "outputId": "891362a6-030e-4032-b76c-d798b4efc086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity': 'I-ORG', 'score': 0.99973315, 'index': 1, 'word': 'Apple', 'start': 0, 'end': 5}, {'entity': 'I-ORG', 'score': 0.9994981, 'index': 2, 'word': 'Inc', 'start': 6, 'end': 9}, {'entity': 'I-LOC', 'score': 0.9995732, 'index': 12, 'word': 'Paris', 'start': 46, 'end': 51}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Question Answering using DistilBERT**"
      ],
      "metadata": {
        "id": "Apb3drsVSTCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a question-answering pipeline using the DistilBERT model\n",
        "question_answerer = pipeline('question-answering', model='distilbert-base-cased-distilled-squad')\n",
        "\n",
        "# Providing a context and a question for question-answering and printing the answer\n",
        "context = \"Hugging Face is a company that specializes in natural language processing.\"\n",
        "question = \"What does Hugging Face specialize in?\"\n",
        "answer = question_answerer(question=question, context=context)\n",
        "print(answer['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdkFPLihFbzH",
        "outputId": "37b5552a-45f2-4f39-ddbf-4d12b8fe0763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "natural language processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1IR-0A5bHBC_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}